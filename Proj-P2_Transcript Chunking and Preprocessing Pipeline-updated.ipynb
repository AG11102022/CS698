{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2502dc4e-8244-4ac5-b026-3daa8a8fa43d",
   "metadata": {},
   "source": [
    "# This section is responsible for:\n",
    "\n",
    "# *1. Cleaning out timestamps,*\n",
    "\n",
    "# *2. Splitting text into overlapping word chunks,*\n",
    "\n",
    "# *3. Estimating the start time of each chunk based on words-per-second rate,\n",
    "\n",
    "# *4. Saving the results into a CSV for later use (e.g., search, embedding, or alignment with video)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1890b4-45da-4397-8ff8-eadcc32082b6",
   "metadata": {},
   "source": [
    "### The goal of this section is to break up long transcripts into smaller, overlapping chunks of text that can be later used for tasks like search, summarization, or question-answering.\n",
    "\n",
    "### Breaking the text into chunks with some overlap helps keep the meaning clear â€” the overlap ensures that important context isn't lost between segments. The script also estimates when each chunk starts in the video, based on how fast people typically speak, so each chunk can be tied back to a specific time in the video. This is useful when someone asks a question and you want to jump to the exact part of the video that answers it. Finally, the code cleans up the transcripts by removing timestamps, so only the actual spoken words are kept for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18f1ce02-c03e-402c-9cc8-3c285b310695",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55cab9c6-6598-4c78-8fec-65e3e936ccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Parameters ---\n",
    "transcript_dir = \"VideoProj_transcripts\"  # From Part 1\n",
    "nlp = spacy.load(\"en_core_web_sm\")  # Use spaCy's small English model\n",
    "\n",
    "# --- Step 1: Segment timestamped entries using spaCy ---\n",
    "def spacy_sentence_segmentation(transcript_data):\n",
    "    sentences = []\n",
    "    for entry in transcript_data:\n",
    "        text = entry['text']\n",
    "        start_time = entry['start']  # Keep timestamp of entry\n",
    "\n",
    "        # Use spaCy to split into sentences\n",
    "        doc = nlp(text)\n",
    "        for sent in doc.sents:\n",
    "            cleaned = sent.text.strip()\n",
    "            if len(cleaned) > 10:  # Filter short/noisy fragments\n",
    "                sentences.append({\n",
    "                    \"text\": cleaned,\n",
    "                    \"start\": int(start_time)\n",
    "                })\n",
    "    return sentences\n",
    "\n",
    "# --- Step 2: Remove repeated/near-identical sentences ---\n",
    "def remove_repeated_sentences(sentences):\n",
    "    seen = set()\n",
    "    unique_sentences = []\n",
    "    for s in sentences:\n",
    "        normalized = s[\"text\"].lower().strip()\n",
    "        if normalized not in seen:\n",
    "            seen.add(normalized)\n",
    "            unique_sentences.append(s)\n",
    "    return unique_sentences\n",
    "\n",
    "# --- Step 3: Process all transcript files ---\n",
    "all_sentences = []\n",
    "\n",
    "for filename in os.listdir(transcript_dir):\n",
    "    if filename.endswith(\".pkl\"):\n",
    "        video_id = filename.split(\"_\")[0]\n",
    "        filepath = os.path.join(transcript_dir, filename)\n",
    "\n",
    "        # Load transcript\n",
    "        with open(filepath, \"rb\") as f:\n",
    "            transcript_data = pickle.load(f)\n",
    "\n",
    "        # Segment + clean\n",
    "        sentences = spacy_sentence_segmentation(transcript_data)\n",
    "        sentences = remove_repeated_sentences(sentences)\n",
    "\n",
    "        # Store structured sentence chunks\n",
    "        for idx, sent in enumerate(sentences):\n",
    "            all_sentences.append({\n",
    "                \"video_id\": video_id,\n",
    "                \"chunk_id\": idx,\n",
    "                \"text\": sent[\"text\"],\n",
    "                \"start\": sent[\"start\"]\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffc33583-e34c-473b-bba9-d255545c82f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Total unique sentence-chunks: 35329 from 80 videos\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-Hv6OPTlUZU</td>\n",
       "      <td>0</td>\n",
       "      <td>so now that we have seen in an earlier</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-Hv6OPTlUZU</td>\n",
       "      <td>1</td>\n",
       "      <td>video the simple RNN kind of</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-Hv6OPTlUZU</td>\n",
       "      <td>2</td>\n",
       "      <td>architecture and we went through a</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-Hv6OPTlUZU</td>\n",
       "      <td>3</td>\n",
       "      <td>simple example of time serious</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-Hv6OPTlUZU</td>\n",
       "      <td>4</td>\n",
       "      <td>prediction I think it's worthwhile</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id  chunk_id                                    text  start\n",
       "0  -Hv6OPTlUZU         0  so now that we have seen in an earlier      0\n",
       "1  -Hv6OPTlUZU         1            video the simple RNN kind of      2\n",
       "2  -Hv6OPTlUZU         2      architecture and we went through a      4\n",
       "3  -Hv6OPTlUZU         3          simple example of time serious      5\n",
       "4  -Hv6OPTlUZU         4      prediction I think it's worthwhile      7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Step 4: Save to CSV for Part 3 ---\n",
    "chunk_df = pd.DataFrame(all_sentences)\n",
    "chunk_df.to_csv(\"VideoProj_chunks.csv\", index=False)\n",
    "\n",
    "# --- Preview ---\n",
    "print(f\" Total unique sentence-chunks: {len(chunk_df)} from {len(os.listdir(transcript_dir))} videos\")\n",
    "chunk_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
