{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e83cd2f-6dab-4610-ac84-c19c9bff9975",
   "metadata": {},
   "source": [
    "# This section:\n",
    "\n",
    "# *1. Loads the saved embedding model, FAISS index, and transcript metadata,*\n",
    "\n",
    "# *2. Encodes a user-provided question into a vector and retrieves the most semantically similar transcript chunks,*\n",
    "\n",
    "# *3. Formats the results with video timestamps and clickable YouTube links for direct navigation to relevant segments.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc74bcc9-43ca-4006-a603-1acb84ed9be2",
   "metadata": {},
   "source": [
    "#### This part enables semantic question-answering from processed transcripts. It loads the previously built FAISS index and metadata, then allows the user to input a natural language question. The question is turned into a vector and compared against the transcript chunk embeddings to find the most semantically similar answers.The result is a short list of relevant transcript segments, each linked to the exact point in the original YouTube video where the answer can be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39730981-d2a2-48f8-801a-cd25e4b14b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\algba\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Part 4: Question Answering with Qdrant Retrieval ---\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c19ec949-8e4d-4975-be57-97e460ba53e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load sentence embedding model (same as Part 3) ---\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# --- Connect to Qdrant ---\n",
    "collection_name = \"video_chunks\"\n",
    "client = QdrantClient(host=\"localhost\", port=6333)\n",
    "\n",
    "# --- Function: Retrieve top-k similar chunks ---\n",
    "def retrieve_similar_chunks(question, top_k=5):\n",
    "    query_vector = model.encode([question]).astype('float32')[0]\n",
    "\n",
    "    results = client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=query_vector,\n",
    "        limit=top_k,\n",
    "        with_payload=True\n",
    "    )\n",
    "\n",
    "    chunks = []\n",
    "    for hit in results:\n",
    "        payload = hit.payload\n",
    "        chunks.append({\n",
    "            \"video_id\": payload.get(\"video_id\"),\n",
    "            \"chunk_id\": payload.get(\"chunk_id\"),\n",
    "            \"text\": payload.get(\"text\"),\n",
    "            \"start\": payload.get(\"start\"),\n",
    "            \"topic\": payload.get(\"topic\"),\n",
    "            \"score\": hit.score\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1202640c-6cbe-48e0-9fee-d3a3460d6734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [Video ID: t9zxmEHGT1s] — Chunk 333 — Start: 0:16:34\n",
      " Jump to: https://www.youtube.com/watch?v=t9zxmEHGT1s&t=994s\n",
      "Text: called reinforcement learning\n",
      "\n",
      " [Video ID: t9zxmEHGT1s] — Chunk 333 — Start: 0:16:34\n",
      " Jump to: https://www.youtube.com/watch?v=t9zxmEHGT1s&t=994s\n",
      "Text: called reinforcement learning\n",
      "\n",
      " [Video ID: gkflVEhnA5s] — Chunk 259 — Start: 0:13:58\n",
      " Jump to: https://www.youtube.com/watch?v=gkflVEhnA5s&t=838s\n",
      "Text: kind of reinforcement learning\n",
      "\n",
      " [Video ID: gkflVEhnA5s] — Chunk 259 — Start: 0:13:58\n",
      " Jump to: https://www.youtube.com/watch?v=gkflVEhnA5s&t=838s\n",
      "Text: kind of reinforcement learning\n",
      "\n",
      " [Video ID: gkflVEhnA5s] — Chunk 32 — Start: 0:01:29\n",
      " Jump to: https://www.youtube.com/watch?v=gkflVEhnA5s&t=89s\n",
      "Text: reinforcement learning kind of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\algba\\AppData\\Local\\Temp\\ipykernel_1080\\2848904726.py:12: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  results = client.search(\n"
     ]
    }
   ],
   "source": [
    "# --- Example usage ---\n",
    "question = \"What is reinforcement learning?\"\n",
    "results_df = retrieve_similar_chunks(question, top_k=5)\n",
    "\n",
    "# --- Display results with YouTube timestamps ---\n",
    "for _, row in results_df.iterrows():\n",
    "    video_id = row[\"video_id\"]\n",
    "    start_sec = int(row[\"start\"])\n",
    "    formatted_time = str(timedelta(seconds=start_sec))\n",
    "    url = f\"https://www.youtube.com/watch?v={video_id}&t={start_sec}s\"\n",
    "\n",
    "    print(f\"\\n [Video ID: {video_id}] — Chunk {row['chunk_id']} — Start: {formatted_time}\")\n",
    "    print(f\" Jump to: {url}\")\n",
    "    print(f\"Text: {row['text']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
